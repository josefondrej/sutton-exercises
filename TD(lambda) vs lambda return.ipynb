{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic notation:\n",
    "\n",
    "$G_{t} = \\sum_{k=0}^{\\infty} \\gamma^{k} R_{t+k+1}$\n",
    "\n",
    "$G_{t:t+n} = R_{t+1} + \\dots + \\gamma^{n-1}R_{t+n} + \\gamma^{n}\\hat{v}(S_{t+n}, w_{t+n-1})$ pro $n > T-t$ definuju jako 0\n",
    "\n",
    "$G_{t}^{\\lambda} = (1-\\lambda) \\sum_{n = 1}^{\\infty} \\lambda^{n-1} G_{t:t+n}$\n",
    "\n",
    "$G_{t}^{\\lambda} = (1-\\lambda) \\sum_{n=1}^{T-t-1}\\lambda^{n-1}G_{t:t+n} + \\lambda^{T-t-1} G_{t}$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 12.1**\n",
    "\n",
    "Just use the formulas above to get\n",
    "\n",
    "$G_{t}^{\\lambda} = R_{t+1} + (1-\\lambda)\\gamma \\hat{v}(S_{t+1}, w_{t}) + \\lambda \\gamma G_{t+1}^{\\lambda}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Offline $\\lambda$-return algorithm\n",
    "\n",
    "makes no changes to the weight vector during the episode, then at the end of the episode whole sequence of offline updates are made according to usual semi-gradient rule\n",
    "\n",
    "$w_{t+1} = w_{t} + \\alpha \\big [G_{t}^{\\lambda} - \\hat{v}(S_{t}, w_{t}) \\big ] \\nabla \\hat{v}(S_{t}, w_{t}),  t = 0, \\dots, T-1$ (12.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TD($\\lambda$) \n",
    "approximates Offline $\\lambda$ return algorithm\n",
    "\n",
    "it updates $w$ on every step of the episode \n",
    "\n",
    "$z_{-1} = 0$\n",
    "\n",
    "$z_{t} = \\gamma \\lambda z_{t-1} + \\nabla \\hat{v}(S_{t}, w_{t}), 0 \\leq t \\leq T$\n",
    "\n",
    "$\\delta_{t} = R_{t+1} + \\gamma \\hat{v}(S_{t+1}, w_{t}) - \\hat{v}(S_{t}, w_{t})$ (12.6)\n",
    "\n",
    "$w_{t+1} = w_{t} + \\alpha \\delta_{t} z_{t}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 12.3**\n",
    "\n",
    "Some insight into how TD($\\lambda$) can closely approximate the offline $\\lambda$-return algorithm can be gained by seeing that the latters error term (in brackets in (12.4)) can be written as the sum of TD errors (12.6) for a single fixed $w$. Show this, following the pattern of (6.6), and using the recursive relationship for the $\\lambda$-return you obtained in Exercise 12.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Equation (6.6): \n",
    "$$\n",
    "\\begin{align}\n",
    "G_{t} - V(S_{t}) & = R_{t+1} + \\gamma G_{t+1} - V(S_{t}) + \\gamma V(S_{t+1}) - \\gamma V(S_{t+1}) \\\\\n",
    "& = \\delta_{t} + \\gamma (G_{t+1} - V(S_{t+1})) \\\\ \n",
    "& = \\delta_{t} + \\gamma \\delta_{t+1} \\gamma^{2} (G_{t+2} - V(S_{t+2})) \\\\ \n",
    "& = \\delta_{t} + \\gamma \\delta_{t+1} \\gamma^{2} \\delta_{t+2} + \\dots +  \\gamma^{T-t}(G_{T} - V(S_{T})) \\\\ \n",
    "& = \\delta_{t} + \\gamma \\delta_{t+1} \\gamma^{2} \\delta_{t+2} + \\dots +  \\gamma^{T-t}(0-0) \\\\ \n",
    "& = \\sum_{k=t}^{T-1} \\gamma^{k-t}\\delta_{k}\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the condition in the algorithm x(terminal) = 0. Following the suggested pattern of (6.6) indeed gives us: \n",
    "\n",
    "$G_{t}^{\\lambda} - \\hat{v}(S_{t},w_{t}) = \\sum_{k = t}^{T-1}\\gamma^{k-t}\\lambda^{k-t}\\tilde{\\delta}_{k}$, \n",
    "\n",
    "where\n",
    "\n",
    "$\\tilde{\\delta_{u}} = R_{u+1} + \\gamma \\hat{v}(S_{u+1}, w_{t}) - \\hat{v}(S_{u}, w_{t})$ (same as $\\delta_{t}$, but $w$ is fixed to $w_{t}$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 12.4**\n",
    "\n",
    "User your result from Exercise 12.3 to show that, if the weight updates over an episode were computed on each step but not actually used to change the weights ($w$ remained fixed), then the sum of TD($\\lambda$)'s weight updates would be the same as the sum of the offline $\\lambda$-return algorithm's updates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For offline $\\lambda$-return algorithm the updates are (forget $\\alpha$ for now): \n",
    "\n",
    "$\\big [ \\sum_{k=t}^{T-1}\\gamma^{k-t}\\lambda^{k-t}\\tilde{\\delta}_{k} \\big ] \\nabla \\hat{v}(S_{t}, w_{t})$\n",
    "\n",
    "$\\big [ \\sum_{k=t+1}^{T-1}\\gamma^{k-t-1}\\lambda^{k-t-1}\\tilde{\\delta}_{k} \\big ] \\nabla \\hat{v}(S_{t+1}, w_{t})$\n",
    "\n",
    "$\\big [ \\sum_{k=t+2}^{T-1}\\gamma^{k-t-2}\\lambda^{k-t-2}\\tilde{\\delta}_{k} \\big ] \\nabla \\hat{v}(S_{2+1}, w_{t})$\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For $TD(\\lambda)$ if we do not update $w$ we get series $z_{t}$\n",
    "\n",
    "$z_{t} = \\nabla \\hat{v}(S_{t}, w_{t})$\n",
    "\n",
    "$z_{t+1} = \\gamma \\lambda \\nabla \\hat{v}(S_{t}, w_{t}) + \\nabla \\hat{v}(S_{t+1}, w_{t})$\n",
    "\n",
    "$z_{t+2} = \\gamma^{2} \\lambda^{2} \\nabla \\hat{v}(S_{t}, w_{t}) + \\gamma \\lambda \\nabla \\hat{v}(S_{t+1}, w_{t}) + \\nabla \\hat{v}(S_{t+2}, w_{t})$\n",
    "\n",
    "and series of updates\n",
    "\n",
    "$\\tilde{\\delta_{t}} \\big [ \\nabla \\hat{v}(S_{t}, w_{t}) \\big ]$\n",
    "\n",
    "$\\tilde{\\delta_{t+1}} \\big [ \\gamma \\lambda \\nabla \\hat{v}(S_{t}, w_{t}) + \\nabla \\hat{v}(S_{t+1}, w_{t}) \\big ]$\n",
    "\n",
    "$\\tilde{\\delta_{t+2}} \\big [ \\gamma^{2} \\lambda^{2} \\nabla \\hat{v}(S_{t}, w_{t}) + \\gamma \\lambda \\nabla \\hat{v}(S_{t+1}, w_{t}) + \\nabla \\hat{v}(S_{t+2}, w_{t}) \\big ]$\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the first update of offline $\\lambda$ is the same as the first column of updates in TD($\\lambda$). The second is the same as the second column etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
