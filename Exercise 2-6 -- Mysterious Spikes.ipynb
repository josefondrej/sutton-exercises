{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the case when we have only 2-armed bandit and $q_{*}(a)$ are generated from normal distribution with mean $\\mu = 0$.\n",
    "\n",
    "If we set the initial values $Q_{0}(a) = 0$ for each $a$, then we select the first lever at random. If the reward is positive (50% chance of this happening) we select the same lever with high probability, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's consider the example when we have k=2 armed bandit. Let's assume the initial distribution of arm values is normal with mean 0. \n",
    "\n",
    "If we use initial values for the arms equal to zero we have 50 percent chance of choosing the best lever on the first try, then our chance of selecting the best lever increases as we gather more information. \n",
    "\n",
    "If we use very optimistic initial values we have also 50 percent chance of choosing the best lever on the first try. Then on the second try, we choose the other lever with very high probability and then "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
